# -*- coding: utf-8 -*-
"""red_wine_quality.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GPTITn9HxfbNy8xvdySZ0xr1GtqlkRbr
"""

from google.colab import drive
drive.mount('/content/drive')

# Importing Dependencies
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# loading the dataset
wine_dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/winequality-red.csv')

wine_dataset.shape

wine_dataset.info()

wine_dataset.head()

# checking for missing values
wine_dataset.isnull().sum()

"""## Data Analysis and Visualization"""

wine_dataset.describe()

wine_dataset['quality'].value_counts().sort_index() #sort_values(ascending=True)

# plotting the wine_dataset quality
sns.catplot(x='quality', data=wine_dataset, kind='count')

# quality 5,6 has got maximum samples

# volatile acidity vs quality
plot = plt.figure(figsize=(5,5))
sns.barplot(x='quality', y='volatile acidity', data=wine_dataset)

# Inference: we can see that there is almost an inverse relationship
# high volatile acidity means less quality

wine_dataset.columns

# citric acid vs quality
plt.figure(figsize=(5,5))
sns.barplot(x='quality', y='citric acid', data=wine_dataset)

# her we can see that the quality of wines improves with increase in citric acid

# correlation among dependant and independant variables
correlation = wine_dataset.corr()

plt.figure(figsize=(10,10))
sns.heatmap(correlation, cbar=True, square=True, fmt='.2f', annot=True, annot_kws={'size':8}, cmap='Blues')
# cbar - color bar on the right side
# fmt - how many floating point values will be there
# annot - values will be printed

# splitting features and target variable
X = wine_dataset.drop(columns=['quality'], axis=1)
y = wine_dataset.quality

"""### Label Binarization"""

y = wine_dataset.quality.apply(lambda y_value : 1 if y_value >= 7 else 0)
y.value_counts()

# spliting training and testing data
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)

print(X.shape, x_train.shape, y.shape, y_train.shape)

# Model training
# using RandomForestClassifier
model = RandomForestClassifier()

model.fit(x_train, y_train)

"""### Model Evaluation"""

# accuracy on test data
x_test_prediction = model.predict(x_test)
print(f"accuracy_score on test data {accuracy_score(y_test, x_test_prediction)}")

# prediction system
input_data = (7.5,0.5,0.36,6.1,0.071,17.0,102.0,0.9978,3.35,0.8,10.5)

# changing the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the data as we are predicting the label for only one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0]==1):
  print('Good Quality Wine')
else:
  print('Bad Quality Wine')

